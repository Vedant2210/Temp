# ğŸ˜ Apache JIRA Scraper

> A robust, modular Python-based scraper to collect, process, and transform issue data from **Apache JIRA** projects (like Hadoop, Spark, and Kafka) into structured **JSONL format** â€” ideal for analytics or LLM training.

---

## ğŸ·ï¸ Badges

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Active-success)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-orange)

---

## ğŸ§  Overview

The **Apache JIRA Scraper** automates the extraction of public issue data from Apacheâ€™s JIRA system using REST APIs.  
It helps researchers, developers, and data engineers create high-quality datasets by scraping issue descriptions, comments, metadata, and transforming them into a **machine-readable** format.

This tool is designed for:
- ğŸ“Š Data collection for ML/NLP research  
- ğŸ§ª Issue tracking & project analytics  
- ğŸ¤– Training datasets for LLM fine-tuning  

---

## âš™ï¸ Tech Stack

| Category | Tools / Libraries |
|-----------|-------------------|
| **Language** | Python 3.10+ |
| **HTTP Requests** | `requests` |
| **Data Handling** | `json`, `pandas` |
| **Logging** | `logging`, custom loggers |
| **Configuration** | `argparse`, `settings.py` |
| **Environment** | `venv` |
| **Output Format** | `.jsonl` |
| **Version Control** | Git & GitHub |

---

## ğŸ§© Features

âœ… Fetches issue data from multiple Apache projects (Hadoop, Spark, Kafka, etc.)  
âœ… Transforms raw JSON into cleaned `.jsonl` format  
âœ… Auto-handles rate limits and retries  
âœ… Logs every step for debugging & monitoring  
âœ… Checkpoint system for fault tolerance  
âœ… Configurable via `config/settings.py`  
âœ… Modular and extensible for new data pipelines  

---

## ğŸ“ Project Structure

```bash
apache-jira-scraper/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py           # Configuration variables (project list, limits)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw JSON data from JIRA API
â”‚   â”œâ”€â”€ processed/            # Cleaned JSONL files
â”‚   â””â”€â”€ checkpoints/          # Track last processed issue ID
â”‚
â”œâ”€â”€ logs/                     # Logging directory
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py            # Core scraper logic
â”‚   â”œâ”€â”€ transform.py          # Data transformation and saving
â”‚   â””â”€â”€ logger.py             # Logging setup
â”‚
â”œâ”€â”€ main.py                   # Entry point for the scraper
â”œâ”€â”€ requirements.txt          # Dependencies list
â””â”€â”€ README.md                 # Project documentation


```
## âš™ï¸ Installation & Setup

Follow these steps to set up and run the scraper locally ğŸ‘‡

---

### 1ï¸âƒ£ Clone the Repository

```
git clone https://github.com/Vedant2210/Apache_Jira_Scraper.git
cd Apache_Jira_Scraper
```
2ï¸âƒ£ Create a Virtual Environment
```
python -m venv venv
```
3ï¸âƒ£ Activate the Virtual Environment
Windows:
```
venv\Scripts\activate
```
macOS/Linux:
```
source venv/bin/activate
```
4ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```
5ï¸âƒ£ Verify Installation
To ensure Python and pip are correctly installed, run:
```
python --version
pip --version
```
Expected output example:
```
nginx

Python 3.10.x
pip 23.x.x
```
â–¶ï¸ Usage Guide
Once setup is complete, run the scraper:
```
python main.py
```
This will start fetching issue data for all projects listed inside your config/settings.py file.

By default, the projects are:
```
DEFAULT_PROJECTS = ["HADOOP", "SPARK", "KAFKA"]
```
Each projectâ€™s issue data will be scraped, transformed, and saved in .jsonl format under the data/processed directory.
